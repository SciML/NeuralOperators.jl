<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>FNO · NeuralOperators.jl</title><meta name="title" content="FNO · NeuralOperators.jl"/><meta property="og:title" content="FNO · NeuralOperators.jl"/><meta property="twitter:title" content="FNO · NeuralOperators.jl"/><meta name="description" content="Documentation for NeuralOperators.jl."/><meta property="og:description" content="Documentation for NeuralOperators.jl."/><meta property="twitter:description" content="Documentation for NeuralOperators.jl."/><meta property="og:url" content="https://docs.sciml.ai/NeuralOperators/stable/tutorials/burgers_fno/"/><meta property="twitter:url" content="https://docs.sciml.ai/NeuralOperators/stable/tutorials/burgers_fno/"/><link rel="canonical" href="https://docs.sciml.ai/NeuralOperators/stable/tutorials/burgers_fno/"/><script data-outdated-warner src="../../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.050/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.8/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="../.."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../../assets/documenter.js"></script><script src="../../search_index.js"></script><script src="../../siteinfo.js"></script><script src="../../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-mocha.css" data-theme-name="catppuccin-mocha"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-macchiato.css" data-theme-name="catppuccin-macchiato"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-frappe.css" data-theme-name="catppuccin-frappe"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-latte.css" data-theme-name="catppuccin-latte"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../../assets/themeswap.js"></script><link href="../../assets/favicon.ico" rel="icon" type="image/x-icon"/></head><body><div id="documenter"><nav class="docs-sidebar"><a class="docs-logo" href="../../"><img src="../../assets/logo.png" alt="NeuralOperators.jl logo"/></a><div class="docs-package-name"><span class="docs-autofit"><a href="../../">NeuralOperators.jl</a></span></div><button class="docs-search-query input is-rounded is-small is-clickable my-2 mx-auto py-1 px-2" id="documenter-search-query">Search docs (Ctrl + /)</button><ul class="docs-menu"><li><a class="tocitem" href="../../">NeuralOperators.jl</a></li><li><span class="tocitem">Pre-built Models</span><ul><li><a class="tocitem" href="../../models/fno/">FNO</a></li><li><a class="tocitem" href="../../models/deeponet/">DeepONet</a></li><li><a class="tocitem" href="../../models/nomad/">NOMAD</a></li></ul></li><li><span class="tocitem">Tutorials</span><ul><li><input class="collapse-toggle" id="menuitem-3-1" type="checkbox" checked/><label class="tocitem" for="menuitem-3-1"><span class="docs-label">Solving Burgers Equation</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../burgers_deeponet/">DeepONet</a></li><li class="is-active"><a class="tocitem" href>FNO</a><ul class="internal"><li><a class="tocitem" href="#Data-Loading"><span>Data Loading</span></a></li><li><a class="tocitem" href="#Model"><span>Model</span></a></li><li><a class="tocitem" href="#Training"><span>Training</span></a></li><li><a class="tocitem" href="#Plotting"><span>Plotting</span></a></li></ul></li></ul></li><li><a class="tocitem" href="../poisson_equation/">Solving Poisson Equation</a></li></ul></li><li><a class="tocitem" href="../../api/">API Reference</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><a class="docs-sidebar-button docs-navbar-link fa-solid fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">Tutorials</a></li><li><a class="is-disabled">Solving Burgers Equation</a></li><li class="is-active"><a href>FNO</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>FNO</a></li></ul></nav><div class="docs-right"><a class="docs-navbar-link" href="https://github.com/SciML/NeuralOperators.jl" title="View the repository on GitHub"><span class="docs-icon fa-brands"></span><span class="docs-label is-hidden-touch">GitHub</span></a><a class="docs-navbar-link" href="https://github.com/SciML/NeuralOperators.jl/blob/main/docs/src/tutorials/burgers_fno.md" title="Edit source on GitHub"><span class="docs-icon fa-solid"></span></a><a class="docs-settings-button docs-navbar-link fa-solid fa-gear" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-article-toggle-button fa-solid fa-chevron-up" id="documenter-article-toggle-button" href="javascript:;" title="Collapse all docstrings"></a></div></header><article class="content" id="documenter-page"><h1 id="Burgers-Equation-using-Fourier-Neural-Operator"><a class="docs-heading-anchor" href="#Burgers-Equation-using-Fourier-Neural-Operator">Burgers Equation using Fourier Neural Operator</a><a id="Burgers-Equation-using-Fourier-Neural-Operator-1"></a><a class="docs-heading-anchor-permalink" href="#Burgers-Equation-using-Fourier-Neural-Operator" title="Permalink"></a></h1><h2 id="Data-Loading"><a class="docs-heading-anchor" href="#Data-Loading">Data Loading</a><a id="Data-Loading-1"></a><a class="docs-heading-anchor-permalink" href="#Data-Loading" title="Permalink"></a></h2><pre><code class="language-julia hljs">using DataDeps, MAT, MLUtils
using PythonCall, CondaPkg # For `gdown`
using Printf

const gdown = pyimport(&quot;gdown&quot;)

register(
    DataDep(
    &quot;Burgers&quot;,
    &quot;&quot;&quot;
    Burgers&#39; equation dataset from
    [fourier_neural_operator](https://github.com/zongyi-li/fourier_neural_operator)

    mapping between initial conditions to the solutions at the last point of time \
    evolution in some function space.

    u(x,0) -&gt; u(x, time_end):

      * `a`: initial conditions u(x,0)
      * `u`: solutions u(x,t_end)
    &quot;&quot;&quot;,
    &quot;https://drive.google.com/uc?id=16a8od4vidbiNR3WtaBPCSZ0T3moxjhYe&quot;,
    &quot;9cbbe5070556c777b1ba3bacd49da5c36ea8ed138ba51b6ee76a24b971066ecd&quot;;
    fetch_method=(url,
        local_dir) -&gt; begin
        pyconvert(String, gdown.download(url, joinpath(local_dir, &quot;Burgers_R10.zip&quot;)))
    end,
    post_fetch_method=unpack
)
)

filepath = joinpath(datadep&quot;Burgers&quot;, &quot;burgers_data_R10.mat&quot;)

const N = 2048
const Δsamples = 2^3
const grid_size = div(2^13, Δsamples)
const T = Float32

file = matopen(filepath)
x_data = reshape(T.(collect(read(file, &quot;a&quot;)[1:N, 1:Δsamples:end])), N, :)
y_data = reshape(T.(collect(read(file, &quot;u&quot;)[1:N, 1:Δsamples:end])), N, :)
close(file)

x_data = hcat(
    repeat(reshape(collect(T, range(0, 1; length=grid_size)), :, 1, 1), 1, 1, N),
    reshape(permutedims(x_data, (2, 1)), grid_size, 1, N)
);
y_data = reshape(permutedims(y_data, (2, 1)), grid_size, 1, N);</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">1024×1×2048 Array{Float32, 3}:
[:, :, 1] =
 0.6834662
 0.6850582
 0.68663555
 0.68819803
 0.6897452
 0.6912767
 0.6927921
 0.6942911
 0.6957732
 0.697238
 ⋮
 0.66854095
 0.6702484
 0.6719444
 0.6736285
 0.6753004
 0.6769599
 0.67860657
 0.68024004
 0.68186

[:, :, 2] =
 0.7511075
 0.75031614
 0.74948686
 0.74862
 0.7477157
 0.7467743
 0.7457962
 0.7447817
 0.74373096
 0.7426446
 ⋮
 0.75649047
 0.756049
 0.75556797
 0.7550476
 0.7544881
 0.75388944
 0.7532519
 0.75257564
 0.75186074

[:, :, 3] =
 -0.41533458
 -0.4158413
 -0.41631535
 -0.416757
 -0.4171665
 -0.41754422
 -0.41789043
 -0.41820538
 -0.4184894
 -0.41874272
  ⋮
 -0.40924993
 -0.4100654
 -0.41084528
 -0.4115898
 -0.4122994
 -0.41297436
 -0.41361505
 -0.41422176
 -0.41479483

;;; … 

[:, :, 2046] =
  0.016046494
  0.008860671
  0.0016381989
 -0.005616474
 -0.012898825
 -0.020204268
 -0.02752816
 -0.034865808
 -0.04221249
 -0.04956345
  ⋮
  0.07838251
  0.071710624
  0.06496665
  0.05815404
  0.051276375
  0.044337366
  0.03734086
  0.030290816
  0.0231913

[:, :, 2047] =
 0.36310026
 0.36462003
 0.36611378
 0.36758128
 0.36902225
 0.3704365
 0.37182376
 0.37318385
 0.37451655
 0.37582165
 ⋮
 0.34829122
 0.35003418
 0.35175335
 0.3534485
 0.35511935
 0.35676563
 0.3583871
 0.35998356
 0.36155468

[:, :, 2048] =
 1.0363716
 1.0398366
 1.0432957
 1.0467485
 1.0501951
 1.0536352
 1.0570688
 1.0604957
 1.0639158
 1.067329
 ⋮
 1.0049305
 1.0084454
 1.0119551
 1.0154597
 1.0189589
 1.0224527
 1.025941
 1.0294236
 1.0329006</code></pre><h2 id="Model"><a class="docs-heading-anchor" href="#Model">Model</a><a id="Model-1"></a><a class="docs-heading-anchor-permalink" href="#Model" title="Permalink"></a></h2><pre><code class="language-julia hljs">using Lux, NeuralOperators, Optimisers,  Random, Reactant

const cdev = cpu_device()
const xdev = reactant_device(; force=true)

fno = FourierNeuralOperator(
    gelu;
    chs = (2, 32, 32, 32, 1),
    modes = (16,)
)
ps, st = Lux.setup(Random.default_rng(), fno) |&gt; xdev;</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">((layer_1 = (weight = Reactant.ConcretePJRTArray{Float32, 3, 1, Reactant.Sharding.ShardInfo{Reactant.Sharding.NoSharding, Nothing}}(Float32[-0.45048642 0.8215421;;; -0.6469188 0.5172023;;; -0.50672746 -0.2251062;;; … ;;; 0.32661134 0.6829613;;; 0.56776494 -0.67940456;;; -0.32555076 0.66041964]), bias = Reactant.ConcretePJRTArray{Float32, 1, 1, Reactant.Sharding.ShardInfo{Reactant.Sharding.NoSharding, Nothing}}(Float32[0.159703, -0.3509462, -0.10126159, 0.39295563, 0.6632423, -0.49430946, -0.21302897, 0.3522459, -0.08633116, -0.12322027  …  -0.645387, 0.45198408, 0.31946394, 0.6437974, -0.6391551, -0.59291124, 0.24596775, 0.23623613, 0.08163769, 0.7027147])), layer_2 = (layer_1 = (layer_1 = (weight = Reactant.ConcretePJRTArray{Float32, 3, 1, Reactant.Sharding.ShardInfo{Reactant.Sharding.NoSharding, Nothing}}(Float32[0.1592321 0.09994179 … 0.045668192 -0.043369077;;; -0.04223319 0.15802586 … 0.2920941 0.23926833;;; -0.2262735 0.16398965 … 0.110363886 -0.2685145;;; … ;;; -0.11430142 -0.19571044 … 0.07444476 0.014765042;;; -0.2560931 0.17501983 … -0.26627886 -0.2982624;;; 0.019384805 -0.009488968 … -0.22348683 0.05007888]), bias = Reactant.ConcretePJRTArray{Float32, 1, 1, Reactant.Sharding.ShardInfo{Reactant.Sharding.NoSharding, Nothing}}(Float32[-0.099463254, 0.099021554, 0.07570716, -0.12149139, -0.08468345, -0.14779498, 0.15397099, 0.12813418, 0.076885395, 0.04182451  …  -0.16394104, 0.07427706, -0.037356015, 0.052519947, 0.09949103, 0.15752755, 0.034493443, -0.07502603, 0.008916187, 0.056339525])), layer_2 = (weight = Reactant.ConcretePJRTArray{ComplexF32, 3, 1, Reactant.Sharding.ShardInfo{Reactant.Sharding.NoSharding, Nothing}}(ComplexF32[-3.0935866f-5 + 7.427574f-5im 2.5712128f-5 + 0.00010859826f0im … 5.8279038f-5 + 3.1768133f-5im -5.7352918f-5 + 4.2948515f-5im; 7.817478f-6 + 9.6212876f-5im -2.053997f-5 + 2.6470807f-5im … 6.062367f-5 + 7.7212484f-5im 3.5994584f-5 + 7.188225f-5im; … ; -2.5089452f-5 + 3.5352736f-5im -2.0307445f-5 + 3.176226f-5im … 1.6763792f-5 + 1.671131f-5im -1.9072104f-5 + 9.588852f-5im; -8.867784f-6 + 6.740003f-5im -5.480225f-5 + 1.704361f-5im … 2.546257f-5 + 0.00011110144f0im 2.8924245f-5 + 6.480141f-5im;;; -4.6620116f-6 + 5.503907f-5im -3.1788673f-5 + 5.746715f-5im … -4.255245f-5 + 2.5514826f-5im -1.2163713f-5 + 0.0001084911f0im; -5.0325485f-5 + 6.0037324f-5im -1.9020823f-5 + 9.9439036f-5im … 2.8261406f-5 + 7.952551f-5im -3.0348187f-5 + 6.481816f-6im; … ; 3.390659f-5 + 8.479695f-5im 2.2994413f-5 + 8.7894216f-5im … -4.54321f-6 + 9.995889f-5im 4.836179f-5 + 9.914721f-5im; 1.7325983f-5 + 9.753192f-5im -2.3943227f-5 + 0.00011992434f0im … -1.573834f-5 + 3.1292897f-5im -4.0550367f-7 + 5.724511f-5im;;; -5.168056f-5 + 9.316314f-5im -2.7360904f-5 + 6.795297f-5im … -3.7739592f-6 + 9.46978f-5im 4.3808453f-5 + 8.446885f-5im; 1.558863f-5 + 7.3348245f-5im -1.5710735f-5 + 0.00011679788f0im … -4.6230525f-5 + 8.479441f-5im -1.6633872f-5 + 8.3185245f-5im; … ; -5.655668f-5 + 1.8663624f-5im 2.0574684f-5 + 1.9723811f-6im … -3.316757f-5 + 3.921982f-5im 2.0167427f-5 + 6.350323f-5im; 5.139286f-5 + 4.71659f-5im 4.8296773f-5 + 2.5602007f-5im … -3.573099f-5 + 7.116767f-5im 2.277203f-5 + 6.413757f-5im;;; … ;;; 3.9063932f-5 + 2.5451169f-5im 4.7108406f-5 + 6.701284f-5im … 6.082144f-5 + 3.0961382f-6im 4.3442735f-5 + 0.000112084796f0im; 4.8696995f-5 + 0.000118203745f0im 2.6181573f-5 + 6.9734975f-5im … 2.7750502f-6 + 0.00010467386f0im 2.7049879f-5 + 7.627361f-5im; … ; -3.8921287f-5 + 7.742296f-5im -5.0675357f-5 + 0.00011953137f0im … 3.2405158f-5 + 1.9503183f-5im 3.949208f-5 + 9.8994584f-5im; 4.7292706f-5 + 0.00011065268f0im 5.314187f-5 + 3.727965f-5im … 8.946663f-7 + 6.126948f-5im 3.7056452f-8 + 4.669484f-6im;;; 2.2937333f-5 + 0.000110391265f0im -1.3447301f-5 + 1.7915248f-5im … -3.7007114f-5 + 0.00010069169f0im 1.7135215f-5 + 3.2327218f-5im; -5.8903825f-5 + 0.00010564915f0im -3.4010664f-6 + 6.378869f-5im … -1.829888f-5 + 7.2804636f-5im 1.7353443f-5 + 9.304722f-5im; … ; 2.512637f-5 + 9.569451f-5im 1.0529853f-5 + 5.9852347f-5im … 5.349939f-5 + 0.000121510384f0im 2.7104768f-5 + 7.3398696f-5im; 3.9732753f-5 + 9.715026f-5im -4.1722065f-5 + 0.00010780814f0im … -5.9163518f-5 + 8.711785f-5im 3.840407f-5 + 7.278397f-5im;;; -3.0485535f-5 + 0.0001139166f0im -5.2329066f-5 + 7.9496596f-5im … 3.8996397f-5 + 1.2555924f-5im -5.7971374f-5 + 8.0581885f-5im; -4.6154906f-5 + 6.969101f-5im 5.394489f-5 + 4.3701853f-5im … -4.6388363f-5 + 2.5771784f-5im 1.3398676f-5 + 9.4362564f-5im; … ; 4.3971697f-5 + 7.320275f-5im -4.5487475f-5 + 3.6319514f-5im … 2.5356276f-6 + 8.446341f-5im 6.929724f-6 + 7.3499665f-5im; 1.8237944f-5 + 4.005417f-5im 3.1376003f-5 + 4.5666675f-6im … -1.7605249f-5 + 2.6312024f-5im -2.3840788f-5 + 9.8645105f-6im]),)),), layer_3 = (layer_1 = (weight = Reactant.ConcretePJRTArray{Float32, 3, 1, Reactant.Sharding.ShardInfo{Reactant.Sharding.NoSharding, Nothing}}(Float32[0.21060213 0.059896532 … 0.19624831 -0.043392293;;; 0.014726169 -0.11724254 … -0.3039345 0.060003042;;; 0.046015456 0.040982544 … -0.28389025 0.2853877;;; … ;;; -0.10491239 -0.13312277 … 0.2663686 0.08861741;;; 0.04598983 -0.27310973 … -0.26096496 0.20156252;;; 0.10925899 -0.16013551 … 0.1184853 -0.029752407]), bias = Reactant.ConcretePJRTArray{Float32, 1, 1, Reactant.Sharding.ShardInfo{Reactant.Sharding.NoSharding, Nothing}}(Float32[-0.1442807, -0.12811695, 0.13583218, 0.022238974, 0.17420095, -0.0434467, -0.15892778, 0.16444685, -0.13335733, -0.022785513  …  -0.095185265, -0.154987, 0.15307882, 0.023175161, 0.08121192, 0.053449873, -0.08707842, 0.15632051, -0.01462542, -0.10958008])), layer_2 = (weight = Reactant.ConcretePJRTArray{Float32, 3, 1, Reactant.Sharding.ShardInfo{Reactant.Sharding.NoSharding, Nothing}}(Float32[0.14130248 -0.08462753 … -0.24829772 0.29430732;;;]), bias = Reactant.ConcretePJRTArray{Float32, 1, 1, Reactant.Sharding.ShardInfo{Reactant.Sharding.NoSharding, Nothing}}(Float32[0.11649686])))), (layer_1 = NamedTuple(), layer_2 = (layer_1 = (layer_1 = NamedTuple(), layer_2 = NamedTuple()),), layer_3 = (layer_1 = NamedTuple(), layer_2 = NamedTuple())))</code></pre><h2 id="Training"><a class="docs-heading-anchor" href="#Training">Training</a><a id="Training-1"></a><a class="docs-heading-anchor-permalink" href="#Training" title="Permalink"></a></h2><pre><code class="language-julia hljs">dataloader = DataLoader((x_data, y_data); batchsize=128, shuffle=true) |&gt; xdev;

function train_model!(model, ps, st, dataloader; epochs=5000)
    train_state = Training.TrainState(model, ps, st, Adam(0.0001f0))

    for epoch in 1:epochs, data in dataloader
        (_, loss, _, train_state) = Training.single_train_step!(
            AutoEnzyme(), MAELoss(), data, train_state; return_gradients=Val(false)
        )

        if epoch % 100 == 1 || epoch == epochs
            @printf(&quot;Epoch %d: loss = %.6e\n&quot;, epoch, loss)
        end
    end

    return train_state.parameters, train_state.states
end

(ps_trained, st_trained) = train_model!(fno, ps, st, dataloader)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">Epoch 1: loss = 4.185350e-01
Epoch 1: loss = 3.847725e-01
Epoch 1: loss = 3.778820e-01
Epoch 1: loss = 3.624157e-01
Epoch 1: loss = 3.924138e-01
Epoch 1: loss = 3.906741e-01
Epoch 1: loss = 3.668880e-01
Epoch 1: loss = 3.759270e-01
Epoch 1: loss = 3.483794e-01
Epoch 1: loss = 3.291906e-01
Epoch 1: loss = 3.745300e-01
Epoch 1: loss = 3.457507e-01
Epoch 1: loss = 3.487275e-01
Epoch 1: loss = 3.202254e-01
Epoch 1: loss = 3.216429e-01
Epoch 1: loss = 2.971081e-01
Epoch 101: loss = 9.917093e-03
Epoch 101: loss = 9.178663e-03
Epoch 101: loss = 1.021164e-02
Epoch 101: loss = 1.078823e-02
Epoch 101: loss = 8.986007e-03
Epoch 101: loss = 1.175524e-02
Epoch 101: loss = 9.373501e-03
Epoch 101: loss = 9.171238e-03
Epoch 101: loss = 1.067433e-02
Epoch 101: loss = 1.076908e-02
Epoch 101: loss = 1.220937e-02
Epoch 101: loss = 9.859804e-03
Epoch 101: loss = 1.063627e-02
Epoch 101: loss = 8.782049e-03
Epoch 101: loss = 1.113888e-02
Epoch 101: loss = 1.094239e-02
Epoch 201: loss = 5.798274e-03
Epoch 201: loss = 6.246480e-03
Epoch 201: loss = 7.820432e-03
Epoch 201: loss = 5.123110e-03
Epoch 201: loss = 5.438905e-03
Epoch 201: loss = 5.268245e-03
Epoch 201: loss = 6.648171e-03
Epoch 201: loss = 6.729436e-03
Epoch 201: loss = 5.174990e-03
Epoch 201: loss = 5.519715e-03
Epoch 201: loss = 5.954529e-03
Epoch 201: loss = 4.878364e-03
Epoch 201: loss = 6.481537e-03
Epoch 201: loss = 5.627160e-03
Epoch 201: loss = 7.092607e-03
Epoch 201: loss = 5.542709e-03
Epoch 301: loss = 3.967932e-03
Epoch 301: loss = 3.693829e-03
Epoch 301: loss = 4.416491e-03
Epoch 301: loss = 3.642369e-03
Epoch 301: loss = 4.081584e-03
Epoch 301: loss = 4.648238e-03
Epoch 301: loss = 4.229440e-03
Epoch 301: loss = 4.022919e-03
Epoch 301: loss = 4.661159e-03
Epoch 301: loss = 3.653183e-03
Epoch 301: loss = 6.051822e-03
Epoch 301: loss = 4.765233e-03
Epoch 301: loss = 3.841510e-03
Epoch 301: loss = 4.098330e-03
Epoch 301: loss = 3.974851e-03
Epoch 301: loss = 4.093516e-03
Epoch 401: loss = 4.757474e-03
Epoch 401: loss = 3.084417e-03
Epoch 401: loss = 2.895908e-03
Epoch 401: loss = 3.617132e-03
Epoch 401: loss = 3.667529e-03
Epoch 401: loss = 3.387585e-03
Epoch 401: loss = 3.203085e-03
Epoch 401: loss = 3.145641e-03
Epoch 401: loss = 3.719418e-03
Epoch 401: loss = 3.251507e-03
Epoch 401: loss = 3.158458e-03
Epoch 401: loss = 3.237715e-03
Epoch 401: loss = 3.495535e-03
Epoch 401: loss = 3.605752e-03
Epoch 401: loss = 3.166524e-03
Epoch 401: loss = 3.050577e-03
Epoch 501: loss = 2.840640e-03
Epoch 501: loss = 2.209575e-03
Epoch 501: loss = 3.726437e-03
Epoch 501: loss = 3.396132e-03
Epoch 501: loss = 2.635113e-03
Epoch 501: loss = 2.640623e-03
Epoch 501: loss = 3.373754e-03
Epoch 501: loss = 2.363693e-03
Epoch 501: loss = 2.119478e-03
Epoch 501: loss = 2.861599e-03
Epoch 501: loss = 2.629561e-03
Epoch 501: loss = 2.465657e-03
Epoch 501: loss = 3.184042e-03
Epoch 501: loss = 3.221159e-03
Epoch 501: loss = 2.753717e-03
Epoch 501: loss = 4.157274e-03
Epoch 601: loss = 2.368766e-03
Epoch 601: loss = 2.356603e-03
Epoch 601: loss = 2.471656e-03
Epoch 601: loss = 3.148256e-03
Epoch 601: loss = 2.441427e-03
Epoch 601: loss = 2.546872e-03
Epoch 601: loss = 2.231170e-03
Epoch 601: loss = 2.582331e-03
Epoch 601: loss = 2.481187e-03
Epoch 601: loss = 2.147832e-03
Epoch 601: loss = 2.733195e-03
Epoch 601: loss = 2.512300e-03
Epoch 601: loss = 2.510229e-03
Epoch 601: loss = 2.822486e-03
Epoch 601: loss = 2.815653e-03
Epoch 601: loss = 2.823850e-03
Epoch 701: loss = 2.468882e-03
Epoch 701: loss = 2.116042e-03
Epoch 701: loss = 2.345831e-03
Epoch 701: loss = 2.100858e-03
Epoch 701: loss = 1.863272e-03
Epoch 701: loss = 2.315642e-03
Epoch 701: loss = 2.754104e-03
Epoch 701: loss = 2.332095e-03
Epoch 701: loss = 2.148258e-03
Epoch 701: loss = 2.214390e-03
Epoch 701: loss = 2.393594e-03
Epoch 701: loss = 2.435651e-03
Epoch 701: loss = 2.609729e-03
Epoch 701: loss = 2.000497e-03
Epoch 701: loss = 2.681854e-03
Epoch 701: loss = 3.073378e-03
Epoch 801: loss = 2.216720e-03
Epoch 801: loss = 2.114980e-03
Epoch 801: loss = 3.258717e-03
Epoch 801: loss = 2.347723e-03
Epoch 801: loss = 1.734598e-03
Epoch 801: loss = 2.048538e-03
Epoch 801: loss = 1.860829e-03
Epoch 801: loss = 2.108214e-03
Epoch 801: loss = 2.291038e-03
Epoch 801: loss = 1.811501e-03
Epoch 801: loss = 2.841326e-03
Epoch 801: loss = 1.915595e-03
Epoch 801: loss = 2.045288e-03
Epoch 801: loss = 1.990997e-03
Epoch 801: loss = 1.966192e-03
Epoch 801: loss = 2.313999e-03
Epoch 901: loss = 1.970550e-03
Epoch 901: loss = 2.437627e-03
Epoch 901: loss = 2.013517e-03
Epoch 901: loss = 2.303343e-03
Epoch 901: loss = 1.618698e-03
Epoch 901: loss = 1.754829e-03
Epoch 901: loss = 2.125461e-03
Epoch 901: loss = 1.983292e-03
Epoch 901: loss = 1.730341e-03
Epoch 901: loss = 1.891645e-03
Epoch 901: loss = 1.788546e-03
Epoch 901: loss = 1.945015e-03
Epoch 901: loss = 2.281211e-03
Epoch 901: loss = 2.031079e-03
Epoch 901: loss = 1.814972e-03
Epoch 901: loss = 2.710624e-03
Epoch 1001: loss = 2.228649e-03
Epoch 1001: loss = 1.877699e-03
Epoch 1001: loss = 1.877699e-03
Epoch 1001: loss = 2.773738e-03
Epoch 1001: loss = 1.940492e-03
Epoch 1001: loss = 1.533787e-03
Epoch 1001: loss = 2.103258e-03
Epoch 1001: loss = 1.758556e-03
Epoch 1001: loss = 1.818465e-03
Epoch 1001: loss = 1.622787e-03
Epoch 1001: loss = 1.456913e-03
Epoch 1001: loss = 1.995120e-03
Epoch 1001: loss = 2.198412e-03
Epoch 1001: loss = 1.617744e-03
Epoch 1001: loss = 1.549392e-03
Epoch 1001: loss = 1.631689e-03
Epoch 1101: loss = 1.959881e-03
Epoch 1101: loss = 1.428727e-03
Epoch 1101: loss = 2.866581e-03
Epoch 1101: loss = 1.269222e-03
Epoch 1101: loss = 1.651709e-03
Epoch 1101: loss = 1.570270e-03
Epoch 1101: loss = 1.505217e-03
Epoch 1101: loss = 1.640540e-03
Epoch 1101: loss = 1.694342e-03
Epoch 1101: loss = 1.808063e-03
Epoch 1101: loss = 1.744017e-03
Epoch 1101: loss = 1.986680e-03
Epoch 1101: loss = 2.029394e-03
Epoch 1101: loss = 1.833246e-03
Epoch 1101: loss = 1.697655e-03
Epoch 1101: loss = 1.642617e-03
Epoch 1201: loss = 1.762966e-03
Epoch 1201: loss = 2.203375e-03
Epoch 1201: loss = 1.430637e-03
Epoch 1201: loss = 1.534107e-03
Epoch 1201: loss = 1.842102e-03
Epoch 1201: loss = 1.572963e-03
Epoch 1201: loss = 1.600378e-03
Epoch 1201: loss = 1.492905e-03
Epoch 1201: loss = 1.622580e-03
Epoch 1201: loss = 1.505764e-03
Epoch 1201: loss = 1.933576e-03
Epoch 1201: loss = 1.765209e-03
Epoch 1201: loss = 1.825863e-03
Epoch 1201: loss = 1.771202e-03
Epoch 1201: loss = 1.623319e-03
Epoch 1201: loss = 1.263949e-03
Epoch 1301: loss = 1.521455e-03
Epoch 1301: loss = 1.784475e-03
Epoch 1301: loss = 1.630623e-03
Epoch 1301: loss = 1.389444e-03
Epoch 1301: loss = 1.335770e-03
Epoch 1301: loss = 1.392465e-03
Epoch 1301: loss = 1.413243e-03
Epoch 1301: loss = 1.664315e-03
Epoch 1301: loss = 1.575814e-03
Epoch 1301: loss = 1.409118e-03
Epoch 1301: loss = 1.657885e-03
Epoch 1301: loss = 1.429734e-03
Epoch 1301: loss = 1.585379e-03
Epoch 1301: loss = 1.753459e-03
Epoch 1301: loss = 2.448737e-03
Epoch 1301: loss = 1.559656e-03
Epoch 1401: loss = 1.353506e-03
Epoch 1401: loss = 1.755896e-03
Epoch 1401: loss = 1.770476e-03
Epoch 1401: loss = 1.245134e-03
Epoch 1401: loss = 1.322479e-03
Epoch 1401: loss = 1.289146e-03
Epoch 1401: loss = 1.276450e-03
Epoch 1401: loss = 1.512281e-03
Epoch 1401: loss = 2.149401e-03
Epoch 1401: loss = 1.201649e-03
Epoch 1401: loss = 1.744251e-03
Epoch 1401: loss = 1.494976e-03
Epoch 1401: loss = 1.124804e-03
Epoch 1401: loss = 1.918261e-03
Epoch 1401: loss = 1.868643e-03
Epoch 1401: loss = 1.459607e-03
Epoch 1501: loss = 1.045904e-03
Epoch 1501: loss = 1.230855e-03
Epoch 1501: loss = 1.631266e-03
Epoch 1501: loss = 1.407735e-03
Epoch 1501: loss = 1.719428e-03
Epoch 1501: loss = 1.215218e-03
Epoch 1501: loss = 2.022030e-03
Epoch 1501: loss = 1.521479e-03
Epoch 1501: loss = 1.448228e-03
Epoch 1501: loss = 1.332037e-03
Epoch 1501: loss = 1.785626e-03
Epoch 1501: loss = 1.443739e-03
Epoch 1501: loss = 1.471193e-03
Epoch 1501: loss = 1.315340e-03
Epoch 1501: loss = 2.008236e-03
Epoch 1501: loss = 1.484865e-03
Epoch 1601: loss = 1.562473e-03
Epoch 1601: loss = 1.479629e-03
Epoch 1601: loss = 1.444736e-03
Epoch 1601: loss = 1.599995e-03
Epoch 1601: loss = 2.245360e-03
Epoch 1601: loss = 1.348244e-03
Epoch 1601: loss = 1.509235e-03
Epoch 1601: loss = 1.444109e-03
Epoch 1601: loss = 1.138279e-03
Epoch 1601: loss = 1.304231e-03
Epoch 1601: loss = 1.580595e-03
Epoch 1601: loss = 1.371278e-03
Epoch 1601: loss = 1.404149e-03
Epoch 1601: loss = 1.285631e-03
Epoch 1601: loss = 1.346319e-03
Epoch 1601: loss = 1.084998e-03
Epoch 1701: loss = 1.279720e-03
Epoch 1701: loss = 1.375170e-03
Epoch 1701: loss = 1.095539e-03
Epoch 1701: loss = 1.490860e-03
Epoch 1701: loss = 1.720856e-03
Epoch 1701: loss = 1.617132e-03
Epoch 1701: loss = 1.210910e-03
Epoch 1701: loss = 1.144128e-03
Epoch 1701: loss = 1.173315e-03
Epoch 1701: loss = 1.285522e-03
Epoch 1701: loss = 1.136986e-03
Epoch 1701: loss = 1.200455e-03
Epoch 1701: loss = 1.879113e-03
Epoch 1701: loss = 1.421138e-03
Epoch 1701: loss = 1.252726e-03
Epoch 1701: loss = 1.601437e-03
Epoch 1801: loss = 1.275103e-03
Epoch 1801: loss = 1.511067e-03
Epoch 1801: loss = 1.460321e-03
Epoch 1801: loss = 1.377765e-03
Epoch 1801: loss = 1.418391e-03
Epoch 1801: loss = 1.815230e-03
Epoch 1801: loss = 1.238627e-03
Epoch 1801: loss = 1.301902e-03
Epoch 1801: loss = 1.158078e-03
Epoch 1801: loss = 1.423882e-03
Epoch 1801: loss = 1.252212e-03
Epoch 1801: loss = 1.105508e-03
Epoch 1801: loss = 2.098602e-03
Epoch 1801: loss = 1.609957e-03
Epoch 1801: loss = 1.277054e-03
Epoch 1801: loss = 1.493840e-03
Epoch 1901: loss = 1.254112e-03
Epoch 1901: loss = 1.324480e-03
Epoch 1901: loss = 1.234732e-03
Epoch 1901: loss = 1.037452e-03
Epoch 1901: loss = 1.505676e-03
Epoch 1901: loss = 1.201180e-03
Epoch 1901: loss = 1.306948e-03
Epoch 1901: loss = 1.199524e-03
Epoch 1901: loss = 1.256920e-03
Epoch 1901: loss = 1.083425e-03
Epoch 1901: loss = 1.210608e-03
Epoch 1901: loss = 1.364433e-03
Epoch 1901: loss = 1.554943e-03
Epoch 1901: loss = 1.128084e-03
Epoch 1901: loss = 1.739243e-03
Epoch 1901: loss = 1.527074e-03
Epoch 2001: loss = 1.159945e-03
Epoch 2001: loss = 1.016486e-03
Epoch 2001: loss = 1.407108e-03
Epoch 2001: loss = 1.351485e-03
Epoch 2001: loss = 1.234989e-03
Epoch 2001: loss = 1.208664e-03
Epoch 2001: loss = 1.216594e-03
Epoch 2001: loss = 1.408006e-03
Epoch 2001: loss = 1.075444e-03
Epoch 2001: loss = 1.137052e-03
Epoch 2001: loss = 1.975943e-03
Epoch 2001: loss = 1.227436e-03
Epoch 2001: loss = 1.334362e-03
Epoch 2001: loss = 1.341814e-03
Epoch 2001: loss = 1.006948e-03
Epoch 2001: loss = 1.109130e-03
Epoch 2101: loss = 1.112077e-03
Epoch 2101: loss = 1.185987e-03
Epoch 2101: loss = 1.174826e-03
Epoch 2101: loss = 9.497050e-04
Epoch 2101: loss = 1.924663e-03
Epoch 2101: loss = 1.102438e-03
Epoch 2101: loss = 1.305323e-03
Epoch 2101: loss = 1.045129e-03
Epoch 2101: loss = 1.588421e-03
Epoch 2101: loss = 1.168560e-03
Epoch 2101: loss = 1.273584e-03
Epoch 2101: loss = 9.904903e-04
Epoch 2101: loss = 1.267075e-03
Epoch 2101: loss = 1.305973e-03
Epoch 2101: loss = 1.173200e-03
Epoch 2101: loss = 9.610846e-04
Epoch 2201: loss = 1.304734e-03
Epoch 2201: loss = 1.000590e-03
Epoch 2201: loss = 1.029098e-03
Epoch 2201: loss = 1.138782e-03
Epoch 2201: loss = 9.688190e-04
Epoch 2201: loss = 1.032326e-03
Epoch 2201: loss = 1.867122e-03
Epoch 2201: loss = 1.413413e-03
Epoch 2201: loss = 1.214494e-03
Epoch 2201: loss = 1.321870e-03
Epoch 2201: loss = 1.175207e-03
Epoch 2201: loss = 1.151920e-03
Epoch 2201: loss = 1.068282e-03
Epoch 2201: loss = 1.322338e-03
Epoch 2201: loss = 1.239152e-03
Epoch 2201: loss = 1.418925e-03
Epoch 2301: loss = 1.136046e-03
Epoch 2301: loss = 1.329093e-03
Epoch 2301: loss = 9.614584e-04
Epoch 2301: loss = 1.219791e-03
Epoch 2301: loss = 1.640761e-03
Epoch 2301: loss = 1.339041e-03
Epoch 2301: loss = 9.934341e-04
Epoch 2301: loss = 1.129620e-03
Epoch 2301: loss = 1.133519e-03
Epoch 2301: loss = 1.012597e-03
Epoch 2301: loss = 1.098131e-03
Epoch 2301: loss = 1.301351e-03
Epoch 2301: loss = 1.119796e-03
Epoch 2301: loss = 9.586937e-04
Epoch 2301: loss = 1.368859e-03
Epoch 2301: loss = 1.192648e-03
Epoch 2401: loss = 1.592224e-03
Epoch 2401: loss = 1.431769e-03
Epoch 2401: loss = 1.270656e-03
Epoch 2401: loss = 1.225939e-03
Epoch 2401: loss = 9.663338e-04
Epoch 2401: loss = 9.424061e-04
Epoch 2401: loss = 1.168425e-03
Epoch 2401: loss = 1.090771e-03
Epoch 2401: loss = 1.174170e-03
Epoch 2401: loss = 1.159967e-03
Epoch 2401: loss = 1.131594e-03
Epoch 2401: loss = 1.057238e-03
Epoch 2401: loss = 1.438172e-03
Epoch 2401: loss = 9.746017e-04
Epoch 2401: loss = 1.107665e-03
Epoch 2401: loss = 1.349632e-03
Epoch 2501: loss = 9.113853e-04
Epoch 2501: loss = 8.903616e-04
Epoch 2501: loss = 1.170020e-03
Epoch 2501: loss = 1.076250e-03
Epoch 2501: loss = 1.322852e-03
Epoch 2501: loss = 1.007740e-03
Epoch 2501: loss = 9.441911e-04
Epoch 2501: loss = 1.088807e-03
Epoch 2501: loss = 9.656341e-04
Epoch 2501: loss = 1.310295e-03
Epoch 2501: loss = 1.018464e-03
Epoch 2501: loss = 1.181269e-03
Epoch 2501: loss = 1.213877e-03
Epoch 2501: loss = 1.656943e-03
Epoch 2501: loss = 1.035237e-03
Epoch 2501: loss = 1.175151e-03
Epoch 2601: loss = 1.121743e-03
Epoch 2601: loss = 1.045633e-03
Epoch 2601: loss = 9.601735e-04
Epoch 2601: loss = 1.122898e-03
Epoch 2601: loss = 1.078439e-03
Epoch 2601: loss = 1.084972e-03
Epoch 2601: loss = 1.880316e-03
Epoch 2601: loss = 1.016381e-03
Epoch 2601: loss = 1.287954e-03
Epoch 2601: loss = 1.343167e-03
Epoch 2601: loss = 9.603467e-04
Epoch 2601: loss = 1.070051e-03
Epoch 2601: loss = 9.470892e-04
Epoch 2601: loss = 9.504441e-04
Epoch 2601: loss = 1.053912e-03
Epoch 2601: loss = 1.012606e-03
Epoch 2701: loss = 1.185279e-03
Epoch 2701: loss = 8.809835e-04
Epoch 2701: loss = 1.050414e-03
Epoch 2701: loss = 1.335592e-03
Epoch 2701: loss = 8.838305e-04
Epoch 2701: loss = 1.055904e-03
Epoch 2701: loss = 8.978727e-04
Epoch 2701: loss = 1.202394e-03
Epoch 2701: loss = 1.081083e-03
Epoch 2701: loss = 1.035520e-03
Epoch 2701: loss = 1.562474e-03
Epoch 2701: loss = 1.035107e-03
Epoch 2701: loss = 1.138574e-03
Epoch 2701: loss = 1.130435e-03
Epoch 2701: loss = 1.262491e-03
Epoch 2701: loss = 1.178605e-03
Epoch 2801: loss = 1.079044e-03
Epoch 2801: loss = 7.253647e-04
Epoch 2801: loss = 1.197167e-03
Epoch 2801: loss = 8.924733e-04
Epoch 2801: loss = 9.901110e-04
Epoch 2801: loss = 1.107486e-03
Epoch 2801: loss = 9.031052e-04
Epoch 2801: loss = 1.090208e-03
Epoch 2801: loss = 1.359191e-03
Epoch 2801: loss = 1.164831e-03
Epoch 2801: loss = 1.109863e-03
Epoch 2801: loss = 1.101157e-03
Epoch 2801: loss = 1.024830e-03
Epoch 2801: loss = 1.001961e-03
Epoch 2801: loss = 1.253687e-03
Epoch 2801: loss = 1.347331e-03
Epoch 2901: loss = 8.027732e-04
Epoch 2901: loss = 1.066418e-03
Epoch 2901: loss = 9.984439e-04
Epoch 2901: loss = 8.573082e-04
Epoch 2901: loss = 1.121745e-03
Epoch 2901: loss = 9.827875e-04
Epoch 2901: loss = 1.748829e-03
Epoch 2901: loss = 1.052320e-03
Epoch 2901: loss = 8.109969e-04
Epoch 2901: loss = 1.150677e-03
Epoch 2901: loss = 1.177506e-03
Epoch 2901: loss = 9.547145e-04
Epoch 2901: loss = 8.713544e-04
Epoch 2901: loss = 1.175292e-03
Epoch 2901: loss = 9.801005e-04
Epoch 2901: loss = 1.076245e-03
Epoch 3001: loss = 9.196493e-04
Epoch 3001: loss = 1.132918e-03
Epoch 3001: loss = 1.271955e-03
Epoch 3001: loss = 1.057799e-03
Epoch 3001: loss = 1.708704e-03
Epoch 3001: loss = 1.121676e-03
Epoch 3001: loss = 9.030733e-04
Epoch 3001: loss = 1.259211e-03
Epoch 3001: loss = 9.582859e-04
Epoch 3001: loss = 1.141438e-03
Epoch 3001: loss = 1.205753e-03
Epoch 3001: loss = 1.215541e-03
Epoch 3001: loss = 9.002800e-04
Epoch 3001: loss = 1.182504e-03
Epoch 3001: loss = 9.416869e-04
Epoch 3001: loss = 1.132553e-03
Epoch 3101: loss = 1.126057e-03
Epoch 3101: loss = 1.231761e-03
Epoch 3101: loss = 1.009945e-03
Epoch 3101: loss = 9.905440e-04
Epoch 3101: loss = 8.459088e-04
Epoch 3101: loss = 1.034195e-03
Epoch 3101: loss = 1.142339e-03
Epoch 3101: loss = 1.021557e-03
Epoch 3101: loss = 1.395932e-03
Epoch 3101: loss = 1.043140e-03
Epoch 3101: loss = 9.571615e-04
Epoch 3101: loss = 1.538311e-03
Epoch 3101: loss = 8.451862e-04
Epoch 3101: loss = 1.119854e-03
Epoch 3101: loss = 9.300926e-04
Epoch 3101: loss = 8.964092e-04
Epoch 3201: loss = 1.520020e-03
Epoch 3201: loss = 1.317200e-03
Epoch 3201: loss = 1.245256e-03
Epoch 3201: loss = 1.336947e-03
Epoch 3201: loss = 1.603705e-03
Epoch 3201: loss = 1.440963e-03
Epoch 3201: loss = 1.384708e-03
Epoch 3201: loss = 1.544393e-03
Epoch 3201: loss = 1.331341e-03
Epoch 3201: loss = 1.143383e-03
Epoch 3201: loss = 1.303567e-03
Epoch 3201: loss = 9.877908e-04
Epoch 3201: loss = 1.130267e-03
Epoch 3201: loss = 1.622785e-03
Epoch 3201: loss = 1.369000e-03
Epoch 3201: loss = 1.026245e-03
Epoch 3301: loss = 1.455510e-03
Epoch 3301: loss = 1.044036e-03
Epoch 3301: loss = 1.671469e-03
Epoch 3301: loss = 9.234045e-04
Epoch 3301: loss = 1.401382e-03
Epoch 3301: loss = 1.113968e-03
Epoch 3301: loss = 1.234094e-03
Epoch 3301: loss = 1.312761e-03
Epoch 3301: loss = 1.312409e-03
Epoch 3301: loss = 1.015052e-03
Epoch 3301: loss = 1.416314e-03
Epoch 3301: loss = 1.256426e-03
Epoch 3301: loss = 1.427995e-03
Epoch 3301: loss = 1.762966e-03
Epoch 3301: loss = 1.276482e-03
Epoch 3301: loss = 1.195618e-03
Epoch 3401: loss = 1.187981e-03
Epoch 3401: loss = 1.047931e-03
Epoch 3401: loss = 7.915623e-04
Epoch 3401: loss = 8.388686e-04
Epoch 3401: loss = 9.935793e-04
Epoch 3401: loss = 1.134310e-03
Epoch 3401: loss = 7.965607e-04
Epoch 3401: loss = 8.975341e-04
Epoch 3401: loss = 9.251002e-04
Epoch 3401: loss = 8.843948e-04
Epoch 3401: loss = 1.172842e-03
Epoch 3401: loss = 1.050328e-03
Epoch 3401: loss = 1.473736e-03
Epoch 3401: loss = 7.316570e-04
Epoch 3401: loss = 7.953452e-04
Epoch 3401: loss = 9.936958e-04
Epoch 3501: loss = 9.097275e-04
Epoch 3501: loss = 9.246566e-04
Epoch 3501: loss = 8.909721e-04
Epoch 3501: loss = 1.055816e-03
Epoch 3501: loss = 9.283270e-04
Epoch 3501: loss = 8.865476e-04
Epoch 3501: loss = 8.964916e-04
Epoch 3501: loss = 1.277233e-03
Epoch 3501: loss = 9.125253e-04
Epoch 3501: loss = 8.929125e-04
Epoch 3501: loss = 1.045233e-03
Epoch 3501: loss = 1.043312e-03
Epoch 3501: loss = 1.115396e-03
Epoch 3501: loss = 7.847386e-04
Epoch 3501: loss = 9.109990e-04
Epoch 3501: loss = 1.028497e-03
Epoch 3601: loss = 9.320331e-04
Epoch 3601: loss = 1.051044e-03
Epoch 3601: loss = 1.188979e-03
Epoch 3601: loss = 9.346702e-04
Epoch 3601: loss = 8.485864e-04
Epoch 3601: loss = 1.349593e-03
Epoch 3601: loss = 1.330472e-03
Epoch 3601: loss = 9.053232e-04
Epoch 3601: loss = 8.315055e-04
Epoch 3601: loss = 1.061579e-03
Epoch 3601: loss = 1.062790e-03
Epoch 3601: loss = 9.474885e-04
Epoch 3601: loss = 1.193457e-03
Epoch 3601: loss = 1.059950e-03
Epoch 3601: loss = 1.414264e-03
Epoch 3601: loss = 9.932629e-04
Epoch 3701: loss = 8.378773e-04
Epoch 3701: loss = 8.714474e-04
Epoch 3701: loss = 7.900648e-04
Epoch 3701: loss = 1.070055e-03
Epoch 3701: loss = 9.602626e-04
Epoch 3701: loss = 9.152938e-04
Epoch 3701: loss = 9.803161e-04
Epoch 3701: loss = 9.733897e-04
Epoch 3701: loss = 8.797158e-04
Epoch 3701: loss = 9.407759e-04
Epoch 3701: loss = 8.828968e-04
Epoch 3701: loss = 1.021718e-03
Epoch 3701: loss = 8.603259e-04
Epoch 3701: loss = 1.330888e-03
Epoch 3701: loss = 8.912109e-04
Epoch 3701: loss = 7.137678e-04
Epoch 3801: loss = 8.049053e-04
Epoch 3801: loss = 6.893312e-04
Epoch 3801: loss = 8.624711e-04
Epoch 3801: loss = 1.464751e-03
Epoch 3801: loss = 9.458779e-04
Epoch 3801: loss = 9.994305e-04
Epoch 3801: loss = 7.957419e-04
Epoch 3801: loss = 1.077611e-03
Epoch 3801: loss = 1.147419e-03
Epoch 3801: loss = 8.856693e-04
Epoch 3801: loss = 7.377728e-04
Epoch 3801: loss = 8.758045e-04
Epoch 3801: loss = 6.787486e-04
Epoch 3801: loss = 8.420334e-04
Epoch 3801: loss = 1.027904e-03
Epoch 3801: loss = 9.550254e-04
Epoch 3901: loss = 8.912431e-04
Epoch 3901: loss = 8.224542e-04
Epoch 3901: loss = 9.692863e-04
Epoch 3901: loss = 9.159156e-04
Epoch 3901: loss = 1.009556e-03
Epoch 3901: loss = 8.506568e-04
Epoch 3901: loss = 9.918977e-04
Epoch 3901: loss = 1.332500e-03
Epoch 3901: loss = 7.883747e-04
Epoch 3901: loss = 1.048248e-03
Epoch 3901: loss = 8.500504e-04
Epoch 3901: loss = 8.395353e-04
Epoch 3901: loss = 9.020439e-04
Epoch 3901: loss = 9.278000e-04
Epoch 3901: loss = 6.987621e-04
Epoch 3901: loss = 9.321679e-04
Epoch 4001: loss = 7.722535e-04
Epoch 4001: loss = 1.075576e-03
Epoch 4001: loss = 1.153894e-03
Epoch 4001: loss = 1.039018e-03
Epoch 4001: loss = 1.280666e-03
Epoch 4001: loss = 1.083957e-03
Epoch 4001: loss = 9.751199e-04
Epoch 4001: loss = 8.705154e-04
Epoch 4001: loss = 9.869894e-04
Epoch 4001: loss = 1.122966e-03
Epoch 4001: loss = 8.660171e-04
Epoch 4001: loss = 9.188825e-04
Epoch 4001: loss = 9.260718e-04
Epoch 4001: loss = 8.581744e-04
Epoch 4001: loss = 9.282510e-04
Epoch 4001: loss = 9.152876e-04
Epoch 4101: loss = 8.997585e-04
Epoch 4101: loss = 7.077559e-04
Epoch 4101: loss = 1.193755e-03
Epoch 4101: loss = 7.447655e-04
Epoch 4101: loss = 1.164671e-03
Epoch 4101: loss = 7.314550e-04
Epoch 4101: loss = 9.336132e-04
Epoch 4101: loss = 1.066037e-03
Epoch 4101: loss = 9.658711e-04
Epoch 4101: loss = 9.625529e-04
Epoch 4101: loss = 7.953075e-04
Epoch 4101: loss = 9.699845e-04
Epoch 4101: loss = 7.357426e-04
Epoch 4101: loss = 8.219873e-04
Epoch 4101: loss = 8.625702e-04
Epoch 4101: loss = 9.400924e-04
Epoch 4201: loss = 8.292103e-04
Epoch 4201: loss = 9.763485e-04
Epoch 4201: loss = 8.547171e-04
Epoch 4201: loss = 1.122445e-03
Epoch 4201: loss = 6.769045e-04
Epoch 4201: loss = 9.339032e-04
Epoch 4201: loss = 7.139824e-04
Epoch 4201: loss = 1.108335e-03
Epoch 4201: loss = 8.256995e-04
Epoch 4201: loss = 8.643613e-04
Epoch 4201: loss = 7.937586e-04
Epoch 4201: loss = 8.366898e-04
Epoch 4201: loss = 8.078598e-04
Epoch 4201: loss = 1.075487e-03
Epoch 4201: loss = 7.391179e-04
Epoch 4201: loss = 8.263579e-04
Epoch 4301: loss = 7.879992e-04
Epoch 4301: loss = 8.215846e-04
Epoch 4301: loss = 7.815681e-04
Epoch 4301: loss = 7.009961e-04
Epoch 4301: loss = 9.961086e-04
Epoch 4301: loss = 9.413288e-04
Epoch 4301: loss = 8.359496e-04
Epoch 4301: loss = 1.211354e-03
Epoch 4301: loss = 9.232472e-04
Epoch 4301: loss = 9.276712e-04
Epoch 4301: loss = 8.940614e-04
Epoch 4301: loss = 7.265118e-04
Epoch 4301: loss = 8.497193e-04
Epoch 4301: loss = 7.330402e-04
Epoch 4301: loss = 8.554048e-04
Epoch 4301: loss = 8.383376e-04
Epoch 4401: loss = 9.759552e-04
Epoch 4401: loss = 8.081865e-04
Epoch 4401: loss = 1.419280e-03
Epoch 4401: loss = 8.970887e-04
Epoch 4401: loss = 7.524972e-04
Epoch 4401: loss = 8.527262e-04
Epoch 4401: loss = 9.104675e-04
Epoch 4401: loss = 1.096990e-03
Epoch 4401: loss = 7.175326e-04
Epoch 4401: loss = 6.222428e-04
Epoch 4401: loss = 8.185322e-04
Epoch 4401: loss = 8.824617e-04
Epoch 4401: loss = 8.668919e-04
Epoch 4401: loss = 9.202688e-04
Epoch 4401: loss = 1.081828e-03
Epoch 4401: loss = 7.246028e-04
Epoch 4501: loss = 7.941246e-04
Epoch 4501: loss = 1.009467e-03
Epoch 4501: loss = 8.580122e-04
Epoch 4501: loss = 9.656493e-04
Epoch 4501: loss = 1.577040e-03
Epoch 4501: loss = 9.423388e-04
Epoch 4501: loss = 1.553127e-03
Epoch 4501: loss = 9.291196e-04
Epoch 4501: loss = 1.271367e-03
Epoch 4501: loss = 1.208332e-03
Epoch 4501: loss = 1.272268e-03
Epoch 4501: loss = 1.167664e-03
Epoch 4501: loss = 1.047346e-03
Epoch 4501: loss = 1.030436e-03
Epoch 4501: loss = 1.135854e-03
Epoch 4501: loss = 8.895291e-04
Epoch 4601: loss = 1.167921e-03
Epoch 4601: loss = 7.869205e-04
Epoch 4601: loss = 9.008977e-04
Epoch 4601: loss = 6.084123e-04
Epoch 4601: loss = 7.266835e-04
Epoch 4601: loss = 7.866961e-04
Epoch 4601: loss = 1.320688e-03
Epoch 4601: loss = 8.784749e-04
Epoch 4601: loss = 9.415029e-04
Epoch 4601: loss = 9.256073e-04
Epoch 4601: loss = 6.794496e-04
Epoch 4601: loss = 9.655405e-04
Epoch 4601: loss = 7.787130e-04
Epoch 4601: loss = 8.093574e-04
Epoch 4601: loss = 7.866581e-04
Epoch 4601: loss = 8.148007e-04
Epoch 4701: loss = 7.792119e-04
Epoch 4701: loss = 7.575364e-04
Epoch 4701: loss = 8.062463e-04
Epoch 4701: loss = 9.549216e-04
Epoch 4701: loss = 7.626334e-04
Epoch 4701: loss = 8.283217e-04
Epoch 4701: loss = 9.141123e-04
Epoch 4701: loss = 9.283746e-04
Epoch 4701: loss = 9.256631e-04
Epoch 4701: loss = 8.016726e-04
Epoch 4701: loss = 1.049048e-03
Epoch 4701: loss = 1.292350e-03
Epoch 4701: loss = 7.066783e-04
Epoch 4701: loss = 7.694432e-04
Epoch 4701: loss = 1.031549e-03
Epoch 4701: loss = 7.977457e-04
Epoch 4801: loss = 9.430710e-04
Epoch 4801: loss = 7.672795e-04
Epoch 4801: loss = 9.413120e-04
Epoch 4801: loss = 7.377340e-04
Epoch 4801: loss = 1.509553e-03
Epoch 4801: loss = 1.049116e-03
Epoch 4801: loss = 8.000893e-04
Epoch 4801: loss = 7.742069e-04
Epoch 4801: loss = 1.040389e-03
Epoch 4801: loss = 8.777980e-04
Epoch 4801: loss = 9.579450e-04
Epoch 4801: loss = 8.691931e-04
Epoch 4801: loss = 8.382373e-04
Epoch 4801: loss = 7.746023e-04
Epoch 4801: loss = 7.366401e-04
Epoch 4801: loss = 7.114041e-04
Epoch 4901: loss = 7.252276e-04
Epoch 4901: loss = 9.146386e-04
Epoch 4901: loss = 6.491487e-04
Epoch 4901: loss = 1.278300e-03
Epoch 4901: loss = 8.207912e-04
Epoch 4901: loss = 6.654545e-04
Epoch 4901: loss = 7.763776e-04
Epoch 4901: loss = 1.076228e-03
Epoch 4901: loss = 7.275846e-04
Epoch 4901: loss = 8.228933e-04
Epoch 4901: loss = 7.461139e-04
Epoch 4901: loss = 9.451012e-04
Epoch 4901: loss = 9.628471e-04
Epoch 4901: loss = 8.334577e-04
Epoch 4901: loss = 8.718034e-04
Epoch 4901: loss = 8.163474e-04
Epoch 5000: loss = 6.563529e-04
Epoch 5000: loss = 6.511994e-04
Epoch 5000: loss = 1.020216e-03
Epoch 5000: loss = 1.343280e-03
Epoch 5000: loss = 7.267331e-04
Epoch 5000: loss = 6.559708e-04
Epoch 5000: loss = 7.275387e-04
Epoch 5000: loss = 7.864579e-04
Epoch 5000: loss = 6.713825e-04
Epoch 5000: loss = 9.841713e-04
Epoch 5000: loss = 9.713834e-04
Epoch 5000: loss = 6.448051e-04
Epoch 5000: loss = 8.715901e-04
Epoch 5000: loss = 7.195423e-04
Epoch 5000: loss = 7.041916e-04
Epoch 5000: loss = 8.377901e-04</code></pre><h2 id="Plotting"><a class="docs-heading-anchor" href="#Plotting">Plotting</a><a id="Plotting-1"></a><a class="docs-heading-anchor-permalink" href="#Plotting" title="Permalink"></a></h2><pre><code class="language-julia hljs">using CairoMakie, AlgebraOfGraphics
const AoG = AlgebraOfGraphics
AoG.set_aog_theme!()

x_data_dev = x_data |&gt; xdev;
y_data_dev = y_data |&gt; xdev;

grid = x_data[:, 1, :]
pred = first(
    Reactant.with_config(;
        convolution_precision=PrecisionConfig.HIGH,
        dot_general_precision=PrecisionConfig.HIGH,
    ) do
        @jit(fno(x_data_dev, ps_trained, st_trained))
    end
) |&gt; cdev

data_sequence, sequence, repeated_grid, label = Float32[], Int[], Float32[], String[]
for i in 1:16
    append!(repeated_grid, vcat(grid[:, i], grid[:, i]))
    append!(sequence, repeat([i], grid_size * 2))
    append!(label, repeat([&quot;Ground Truth&quot;], grid_size))
    append!(label, repeat([&quot;Predictions&quot;], grid_size))
    append!(data_sequence, vec(y_data[:, 1, i]))
    append!(data_sequence, vec(pred[:, 1, i]))
end
plot_data = (; data_sequence, sequence, repeated_grid, label)

draw(
    AoG.data(plot_data) *
    mapping(
        :repeated_grid =&gt; L&quot;x&quot;,
        :data_sequence =&gt; L&quot;u(x)&quot;;
        color=:label =&gt; &quot;&quot;,
        layout=:sequence =&gt; nonnumeric,
        linestyle=:label =&gt; &quot;&quot;,
    ) *
    visual(Lines; linewidth=4),
    scales(; Color=(; palette=:tab10), LineStyle = (; palette = [:solid, :dash, :dot]));
    figure=(;
        size=(1024, 1024),
        title=&quot;Using FNO to solve the Burgers equation&quot;,
        titlesize=25,
    ),
    axis=(; xlabelsize=25, ylabelsize=25),
    legend=(; label=L&quot;u(x)&quot;, position=:bottom, labelsize=20),
)</code></pre><img src="3e2c6ca6.png" alt="Example block output"/></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../burgers_deeponet/">« DeepONet</a><a class="docs-footer-nextpage" href="../poisson_equation/">Solving Poisson Equation »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="auto">Automatic (OS)</option><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option><option value="catppuccin-latte">catppuccin-latte</option><option value="catppuccin-frappe">catppuccin-frappe</option><option value="catppuccin-macchiato">catppuccin-macchiato</option><option value="catppuccin-mocha">catppuccin-mocha</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 1.12.0 on <span class="colophon-date" title="Tuesday 10 June 2025 17:22">Tuesday 10 June 2025</span>. Using Julia version 1.11.5.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
